#!/usr/bin/env python3
"""
SlideGrinder - A tool that converts PDFs or URLs into presentation slides
"""

import argparse
import os
import sys
import re
from pathlib import Path
from typing import List, Optional

try:
    from PyPDF2 import PdfReader
except ImportError:
    PdfReader = None

try:
    import requests
    from bs4 import BeautifulSoup
except ImportError:
    requests = None
    BeautifulSoup = None


def extract_text_from_pdf(pdf_path: str) -> str:
    """Extract text content from a PDF file."""
    if PdfReader is None:
        raise ImportError("PyPDF2 is required for PDF processing. Install it with: pip install pypdf2")
    
    try:
        reader = PdfReader(pdf_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except Exception as e:
        raise Exception(f"Error reading PDF: {e}")


def extract_text_from_url(url: str) -> str:
    """Extract text content from a URL."""
    if requests is None or BeautifulSoup is None:
        raise ImportError("requests and beautifulsoup4 are required for URL processing. Install them with: pip install requests beautifulsoup4")
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style", "nav", "footer", "header"]):
            script.decompose()
        
        # Get text from article, main content, or body
        main_content = soup.find('article') or soup.find('main') or soup.find('body')
        if main_content:
            text = main_content.get_text()
        else:
            text = soup.get_text()
        
        # Clean up whitespace
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = '\n'.join(chunk for chunk in chunks if chunk)
        
        return text
    except Exception as e:
        raise Exception(f"Error fetching URL: {e}")


def process_content_to_slides(content: str, max_slides: int = 10) -> List[dict]:
    """
    Process content and extract key points to create slides.
    
    Returns a list of slide dictionaries with 'title' and 'content'.
    """
    slides = []
    
    # Split content into paragraphs
    paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
    
    if not paragraphs:
        paragraphs = [p.strip() for p in content.split('\n') if p.strip() and len(p.strip()) > 20]
    
    # First slide: Title (use first substantial line as title)
    title = "Presentation"
    for para in paragraphs[:5]:
        if len(para) < 100 and len(para) > 5:
            title = para
            paragraphs.remove(para)
            break
    
    slides.append({
        'title': title,
        'content': ['Generated by SlideGrinder']
    })
    
    # Group paragraphs into slides
    current_slide_content = []
    current_slide_title = None
    
    for para in paragraphs:
        # Check if this looks like a heading (short, ends with certain patterns)
        is_heading = (len(para) < 80 and 
                     (para[0].isupper() if para else False) and
                     not para.endswith('.'))
        
        if is_heading and len(slides) < max_slides:
            # Save previous slide if it has content
            if current_slide_content and current_slide_title:
                slides.append({
                    'title': current_slide_title,
                    'content': current_slide_content
                })
            
            # Start new slide
            current_slide_title = para
            current_slide_content = []
        else:
            # Add content to current slide
            if not current_slide_title:
                current_slide_title = f"Slide {len(slides) + 1}"
            
            # Split long paragraphs into bullet points
            if len(para) > 200:
                sentences = re.split(r'[.!?]+', para)
                for sentence in sentences:
                    sentence = sentence.strip()
                    if sentence and len(sentence) > 10:
                        current_slide_content.append(sentence)
            else:
                current_slide_content.append(para)
            
            # If slide has enough content, save it
            if len(current_slide_content) >= 5 and len(slides) < max_slides:
                slides.append({
                    'title': current_slide_title,
                    'content': current_slide_content
                })
                current_slide_title = None
                current_slide_content = []
    
    # Add remaining content as final slide
    if current_slide_content and current_slide_title and len(slides) < max_slides:
        slides.append({
            'title': current_slide_title,
            'content': current_slide_content
        })
    
    # Ensure we have at least a few slides
    if len(slides) < 2:
        # Split remaining paragraphs into slides
        chunk_size = max(1, len(paragraphs) // 3)
        for i in range(0, min(len(paragraphs), chunk_size * 3), chunk_size):
            chunk = paragraphs[i:i+chunk_size]
            if chunk:
                slides.append({
                    'title': f"Key Points {len(slides)}",
                    'content': chunk
                })
    
    return slides[:max_slides]


def generate_slide_markdown(slide: dict, slide_number: int) -> str:
    """Generate markdown content for a single slide."""
    md = f"# Slide {slide_number}: {slide['title']}\n\n"
    
    for point in slide['content']:
        # Clean up the point
        point = point.strip()
        if point:
            md += f"- {point}\n"
    
    md += "\n---\n\n"
    return md


def generate_slide_html(slide: dict, slide_number: int) -> str:
    """Generate HTML content for a single slide."""
    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Slide {slide_number}: {slide['title']}</title>
    <style>
        body {{
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .slide {{
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #333;
            border-bottom: 3px solid #4CAF50;
            padding-bottom: 10px;
        }}
        ul {{
            line-height: 1.8;
            font-size: 18px;
        }}
        li {{
            margin: 10px 0;
        }}
        .slide-number {{
            color: #666;
            font-size: 14px;
        }}
    </style>
</head>
<body>
    <div class="slide">
        <div class="slide-number">Slide {slide_number}</div>
        <h1>{slide['title']}</h1>
        <ul>
"""
    
    for point in slide['content']:
        point = point.strip()
        if point:
            html += f"            <li>{point}</li>\n"
    
    html += """        </ul>
    </div>
</body>
</html>
"""
    return html


def save_slides(slides: List[dict], output_dir: str, format_type: str = "both"):
    """Save slides to the output directory."""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print(f"Generating {len(slides)} slides in {output_dir}...")
    
    # Generate markdown file with all slides
    if format_type in ["markdown", "both"]:
        markdown_file = output_path / "slides.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            for i, slide in enumerate(slides, 1):
                f.write(generate_slide_markdown(slide, i))
        print(f"  ✓ Created {markdown_file}")
    
    # Generate individual HTML files for each slide
    if format_type in ["html", "both"]:
        for i, slide in enumerate(slides, 1):
            html_file = output_path / f"slide_{i:02d}.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(generate_slide_html(slide, i))
        print(f"  ✓ Created {len(slides)} HTML slides")
    
    # Create an index file
    if format_type in ["html", "both"]:
        index_file = output_path / "index.html"
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write("""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>SlideGrinder Presentation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }
        h1 {
            color: #333;
        }
        .slide-list {
            list-style: none;
            padding: 0;
        }
        .slide-list li {
            margin: 10px 0;
        }
        .slide-list a {
            display: block;
            padding: 15px;
            background-color: #4CAF50;
            color: white;
            text-decoration: none;
            border-radius: 4px;
        }
        .slide-list a:hover {
            background-color: #45a049;
        }
    </style>
</head>
<body>
    <h1>SlideGrinder Presentation</h1>
    <ul class="slide-list">
""")
            for i, slide in enumerate(slides, 1):
                f.write(f'        <li><a href="slide_{i:02d}.html">Slide {i}: {slide["title"]}</a></li>\n')
            f.write("""    </ul>
</body>
</html>
""")
        print(f"  ✓ Created {index_file}")
    
    print(f"\nSlides generated successfully in: {output_path.absolute()}")


def main():
    """Main entry point for the SlideGrinder CLI."""
    parser = argparse.ArgumentParser(
        description="SlideGrinder - Convert PDFs or URLs into presentation slides",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  slidegrinder document.pdf
  slidegrinder https://example.com/article
  slidegrinder document.pdf -o my_slides
  slidegrinder https://blog.com/post -o output -f html
  slidegrinder file.pdf -n 15
        """
    )
    
    parser.add_argument(
        'input',
        help='Input PDF file path or URL'
    )
    
    parser.add_argument(
        '-o', '--output',
        default='slides',
        help='Output directory for slides (default: slides)'
    )
    
    parser.add_argument(
        '-f', '--format',
        choices=['markdown', 'html', 'both'],
        default='both',
        help='Output format (default: both)'
    )
    
    parser.add_argument(
        '-n', '--num-slides',
        type=int,
        default=10,
        help='Maximum number of slides to generate (default: 10)'
    )
    
    args = parser.parse_args()
    
    try:
        # Determine input type and extract content
        print(f"Processing input: {args.input}")
        
        if args.input.startswith('http://') or args.input.startswith('https://'):
            print("Detected URL input, fetching content...")
            content = extract_text_from_url(args.input)
        elif os.path.isfile(args.input):
            print("Detected PDF file, extracting text...")
            content = extract_text_from_pdf(args.input)
        else:
            print(f"Error: Input '{args.input}' is neither a valid URL nor an existing file.")
            return 1
        
        if not content or len(content.strip()) < 50:
            print("Error: Could not extract sufficient content from input.")
            return 1
        
        print(f"Extracted {len(content)} characters of content.")
        
        # Process content into slides
        print("Processing content into slides...")
        slides = process_content_to_slides(content, max_slides=args.num_slides)
        
        if not slides:
            print("Error: Could not generate slides from content.")
            return 1
        
        # Save slides
        save_slides(slides, args.output, args.format)
        
        return 0
        
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
